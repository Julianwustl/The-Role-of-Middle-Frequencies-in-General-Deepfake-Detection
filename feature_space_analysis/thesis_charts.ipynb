{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analyse the Classification performance under Frequency Manipulations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR = \"/home/wustl/Dummy/Wustl/Deepfake/MasterThesis\"  # specify WORKDIR here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json\n",
    "import os \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from paper_utils import get_figsize, configure_matplotlib, create_subplot_mosaic\n",
    "from calculate_MMD import get_files_from_directory,get_files_from_sub_directory\n",
    "\n",
    "\n",
    "Generators = [\"ProGAN\", \"StyleGAN\", \"ProjectedGAN\", \"Diff-StyleGAN2\", \"Diff-ProjectedGAN\", \"DDPM\", \"IDDPM\", \"ADM\", \"PNDM\", \"LDM\",\"coco\", \"all\",\"gan\",\"diff\"]#\n",
    "\n",
    "Gans = [\"ProGAN\", \"StyleGAN\", \"ProjectedGAN\", \"Diff-StyleGAN2\", \"Diff-ProjectedGAN\"]\n",
    "Diffs = [\"DDPM\", \"IDDPM\", \"ADM\", \"PNDM\", \"LDM\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_matplotlib(\n",
    "    rc={\n",
    "        \"xtick.labelbottom\": False,\n",
    "        \"xtick.bottom\": True,\n",
    "        \"xtick.labeltop\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"ytick.right\": False,\n",
    "        \"figure.constrained_layout.use\": False,\n",
    "        \"savefig.pad_inches\": 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def create_dataframe_ce(files):\n",
    "    experiments = {}\n",
    "    path_names = []\n",
    "    for experiment_name, files in files.items():\n",
    "        for file in files:\n",
    "            parts = file.split(\"/\")[-1].split(\"_\")\n",
    "            generator_type = parts[-1].split(\".\")[0]\n",
    "            model_name = parts[0]\n",
    "            \n",
    "            try:\n",
    "                with open(file, \"r\") as input_file:  # Assuming JSON file\n",
    "                    results = json.load(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            experiments.setdefault(\n",
    "                model_name, {}).setdefault(\n",
    "                    experiment_name, {}).setdefault(\n",
    "                        generator_type, {key: \n",
    "                                        {metric: metric_value for metrics in value for metric, metric_value in metrics.items()} \n",
    "                                        for step in results for key, value in step.items()\n",
    "                                        })      \n",
    "\n",
    "    data = []\n",
    "    for encoder_name, experiment_dict in experiments.items():\n",
    "        for experiment_name, generator_dict in experiment_dict.items():\n",
    "            for generator_type, metrics_dict in generator_dict.items():\n",
    "                for number, metrics in metrics_dict.items():\n",
    "                    # Create a dictionary for each combination\n",
    "                    flattened_dict = {\n",
    "                        'Encoder': encoder_name,\n",
    "                        'Experiment': experiment_name,\n",
    "                        'Generator': generator_type,\n",
    "                        'Number': number\n",
    "                    }\n",
    "                    # Add all metrics to this dictionary\n",
    "                    flattened_dict.update(metrics)\n",
    "                    data.append(flattened_dict)\n",
    "\n",
    "    # Converting to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df['tendency_to_overclassify_positive'] = 1 - df['test_precision']\n",
    "        \n",
    "    df['tendency_to_overclassify_negative'] = 1 - df['test_recall']\n",
    "    df.to_csv(\"classification_results.csv\")\n",
    "    return df\n",
    "\n",
    "def create_df_test(files):\n",
    "    experiments = {}\n",
    "    path_names = []\n",
    "    for experiment_name, files in files.items():\n",
    "        for file in files:\n",
    "            parts = file.split(\"/\")[-1].split(\"_\")\n",
    "            generator_type = parts[-1].split(\".\")[0]\n",
    "            model_name = parts[0]\n",
    "            \n",
    "            try:\n",
    "                with open(file, \"r\") as input_file:  # Assuming JSON file\n",
    "                    results = json.load(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file}: {e}\")\n",
    "                continue\n",
    "\n",
    "            experiments.setdefault(\n",
    "                model_name, {}).setdefault(\n",
    "                    experiment_name, {}).setdefault(\n",
    "                        generator_type, {key: \n",
    "                                     {metric: metric_value for metrics in values \n",
    "                                      for metric, metric_value in metrics.items()} \n",
    "                                     for key,values in results.items()\n",
    "                                     })      \n",
    "\n",
    "    data = []\n",
    "    for encoder_name, experiment_dict in experiments.items():\n",
    "        for experiment_name, generator_dict in experiment_dict.items():\n",
    "            for generator_type, metrics_dict in generator_dict.items():\n",
    "                for number, metrics in metrics_dict.items():\n",
    "                    # Create a dictionary for each combination\n",
    "                    flattened_dict = {\n",
    "                        'Encoder': encoder_name,\n",
    "                        'Experiment': experiment_name,\n",
    "                        'Generator': generator_type,\n",
    "                        'Number': number\n",
    "                    }\n",
    "                    # Add all metrics to this dictionary\n",
    "                    flattened_dict.update(metrics)\n",
    "                    data.append(flattened_dict)\n",
    "\n",
    "    # Converting to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df['tendency_to_overclassify_positive'] = 1 - df['test_precision']\n",
    "        \n",
    "    df['tendency_to_overclassify_negative'] = 1 - df['test_recall']\n",
    "    df.to_csv(\"classification_results.csv\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "path_names = []\n",
    "base_input_folder = \"/home/wustl/Dummy/Wustl/Deepfake/MasterThesis/results/classification/butt_low_5_ce\"\n",
    "all_files_butt_low_ce = get_files_from_directory(base_input_folder)\n",
    "base_input_folder = \"/home/wustl/Dummy/Wustl/Deepfake/MasterThesis/results/classification/butt_low_middle_freq_ce\"\n",
    "all_files_but_low_per = get_files_from_directory(base_input_folder)\n",
    "\n",
    "df_ce = create_dataframe_ce(all_files_butt_low_ce)\n",
    "df_per = create_df_test(all_files_but_low_per)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the two generators.\n",
    "\n",
    "First we want to understand how the two generators trained on the specific data behave when no filters are applied. Here we want to see if under normal condiations, which model handles the case of new type of generators better, see if there are any tendencies to overclassify either fake or real. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter DataFrame for rows where 'Number' is \"no\"\n",
    "df_filtered = df_ce[df_ce['Number'] == \"no\"]\n",
    "\n",
    "Test_Columns = [\"ProGAN\", \"StyleGAN\", \"ProjectedGAN\", \"Diff-StyleGAN2\", \"Diff-ProjectedGAN\", \"DDPM\", \"IDDPM\", \"ADM\", \"PNDM\", \"LDM\", \"coco\"]\n",
    "#Generators = Test_Columns.copy()  # Assuming Generators should be the same as Test_Columns initially\n",
    "\n",
    "# Assuming we have two models: Model A and Model B\n",
    "model_a = \"OpenClip\"  # Replace with the actual key for Model A\n",
    "model_b = \"DinoV2\"  # Replace with the actual key for Model B\n",
    "\n",
    "metrics = ['test_roc_auc']  # List of metrics\n",
    "\n",
    "# Create a figure with subplots for each metric\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) # Adjust the figure size as needed\n",
    "# Iterate over each metric\n",
    "\n",
    "def create_heatmap(df, metric, Generators, Test_Columns, model_a, ax):\n",
    "    df_modified = df.copy()\n",
    "    df_modified[metric] *= 100\n",
    "    pivot_a = df_modified[df_modified['Encoder'] == model_a].pivot(index='Generator', columns='Experiment', values=metric)\n",
    "    pivot_a['AVG'] = pivot_a.mean(axis=1)\n",
    "    pivot_a.loc['AVG'] = pivot_a.mean(axis=0)\n",
    "\n",
    "    Generators_with_avg = Generators + ['AVG']\n",
    "    Test_Columns_with_avg = Test_Columns + ['AVG']\n",
    "\n",
    "    # Reindex pivot table to include the 'AVG' row and column\n",
    "    pivot_a = pivot_a.reindex(index=Test_Columns_with_avg, columns=Generators_with_avg).fillna(0)\n",
    "\n",
    "    sns.heatmap(\n",
    "        pivot_a,\n",
    "        xticklabels=[label.split(\"_\")[-1] for label in pivot_a.columns],\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 10.5},\n",
    "        fmt=\".1f\",\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        linewidths=1,\n",
    "        #cmap=plt.cm.Reds_r,\n",
    "        ax=ax,\n",
    "        vmin=0,\n",
    "        vmax=100\n",
    "    )\n",
    "\n",
    "    ax.set_xticklabels(Generators_with_avg, rotation=45, fontsize=11)\n",
    "    ax.set_yticklabels(Test_Columns_with_avg, fontsize=11)\n",
    "    ax.set_xlabel(\"Fine-tuned on\")\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.set_ylabel(\"Tested on\")\n",
    "    ax.grid(False, which='minor')\n",
    "    # Adding lines to separate sections of the heatmap\n",
    "    ax.vlines([5, 10], ymin=0, ymax=len(Test_Columns_with_avg), colors=[\"k\"], linestyles=[\"solid\"], linewidths=[0.5])\n",
    "    ax.hlines([5], xmin=0, xmax=len(Generators_with_avg), colors=[\"k\"], linestyles=[\"solid\"], linewidths=[0.5])\n",
    "\n",
    "# df_filtered = df_ce[df_ce['Number'] == \"185\"].reset_index(drop=True)\n",
    "# df_no_filtered = df_ce[df_ce['Number'] == \"no\"].reset_index(drop=True)\n",
    "# df_filtered['test_acc'] = df_filtered.groupby(['Encoder', 'Generator', 'Experiment'])['test_acc'].transform('max')\n",
    "# df_filtered[\"test_acc\"] = pd.to_numeric(df_filtered[\"test_acc\"]) - pd.to_numeric(df_no_filtered[\"test_acc\"])\n",
    "# print(df_filtered[\"test_acc\"])\n",
    "create_heatmap(df_filtered,\"test_pd_01\",Generators,Test_Columns,model_a,ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter DataFrame for rows where 'Number' is \"no\"\n",
    "df_filtered = df_ce[df_ce['Number'] == \"no\"]\n",
    "\n",
    "Test_Columns = [\"ProGAN\", \"StyleGAN\", \"ProjectedGAN\", \"Diff-StyleGAN2\", \"Diff-ProjectedGAN\", \"DDPM\", \"IDDPM\", \"ADM\", \"PNDM\", \"LDM\", \"coco\"]\n",
    "#Generators = Test_Columns.copy()  # Assuming Generators should be the same as Test_Columns initially\n",
    "\n",
    "# Assuming we have two models: Model A and Model B\n",
    "model_a = \"OpenClip\"  # Replace with the actual key for Model A\n",
    "model_b = \"DinoV2\"  # Replace with the actual key for Model B\n",
    "\n",
    "metrics = ['test_acc']  # List of metrics\n",
    "\n",
    "# Create a figure with subplots for each metric\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) # Adjust the figure size as needed\n",
    "# Iterate over each metric\n",
    "\n",
    "def create_heatmap(df, metric, Generators, Test_Columns, model_a, ax):\n",
    "    df_modified = df.copy()\n",
    "    df_modified[metric] *= 100\n",
    "    pivot_a = df_modified[df_modified['Encoder'] == model_a].pivot(index='Generator', columns='Experiment', values=metric)\n",
    "    pivot_a['AVG'] = pivot_a.mean(axis=1)\n",
    "    pivot_a.loc['AVG'] = pivot_a.mean(axis=0)\n",
    "\n",
    "    Generators_with_avg = Generators + ['AVG']\n",
    "    Test_Columns_with_avg = Test_Columns + ['AVG']\n",
    "\n",
    "    # Reindex pivot table to include the 'AVG' row and column\n",
    "    pivot_a = pivot_a.reindex(index=Test_Columns_with_avg, columns=Generators_with_avg).fillna(0)\n",
    "\n",
    "    sns.heatmap(\n",
    "        pivot_a,\n",
    "        xticklabels=[label.split(\"_\")[-1] for label in pivot_a.columns],\n",
    "        annot=True,\n",
    "        annot_kws={\"fontsize\": 10.5},\n",
    "        fmt=\".1f\",\n",
    "        cbar=False,\n",
    "        square=True,\n",
    "        linewidths=1,\n",
    "        #cmap=plt.cm.Reds_r,\n",
    "        ax=ax,\n",
    "        vmin=df_modified[metric].min(),\n",
    "        vmax=df_modified[metric].max()\n",
    "    )\n",
    "\n",
    "    ax.set_xticklabels(Generators_with_avg, rotation=45, fontsize=11)\n",
    "    ax.set_yticklabels(Test_Columns_with_avg, fontsize=11)\n",
    "    ax.set_xlabel(\"Fine-tuned on\")\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.set_ylabel(\"Tested on\")\n",
    "    ax.grid(False, which='minor')\n",
    "    # Adding lines to separate sections of the heatmap\n",
    "    ax.vlines([5, 10], ymin=0, ymax=len(Test_Columns_with_avg), colors=[\"k\"], linestyles=[\"solid\"], linewidths=[0.5])\n",
    "    ax.hlines([5], xmin=0, xmax=len(Generators_with_avg), colors=[\"k\"], linestyles=[\"solid\"], linewidths=[0.5])\n",
    "\n",
    "df_filtered = df_ce[df_ce['Number'] == \"185\"].reset_index(drop=True)\n",
    "df_no_filtered = df_ce[df_ce['Number'] == \"no\"].reset_index(drop=True)\n",
    "\n",
    "df_filtered[\"test_acc\"] = pd.to_numeric(df_filtered[\"test_acc\"]) - pd.to_numeric(df_no_filtered[\"test_acc\"])\n",
    "print(df_filtered[\"test_acc\"])\n",
    "create_heatmap(df_filtered,\"test_acc\",Generators,Test_Columns,model_a,ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtered = df[df[\"Generator\"] == \"ADM\"]\n",
    "\n",
    "average_acc_by_model_filter = df_filtered.groupby(['Encoder', 'Number'])['test_acc'].max()\n",
    "\n",
    "# Find the filter with the maximum average accuracy for each model\n",
    "max_average_acc_by_model = average_acc_by_model_filter.groupby(level=0).idxmax()\n",
    "max_average_values_by_model = average_acc_by_model_filter.groupby(level=0).max()\n",
    "\n",
    "# Display the results\n",
    "print(f\"The filters with the maximum average accuracy for each model are:\\n{max_average_acc_by_model}\")\n",
    "print(f\"The maximum average accuracy values for each model are:\\n{max_average_values_by_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that clip has bigger problems handling diffusion trained models when trained on Gan generated data. Yet, clip can handle coco better when trained on gans and diffusion repectively. We can observe that clip tends classify images as real when faced with new type of generators. \n",
    "\n",
    "So in the following section, we should seperate between gan trained and diff trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see, how the models behave under the context of domain and generator shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIFF Generated Gan Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "filtered_data = df_ce[(df_ce['Experiment'] == 'ADM') & (df_ce['Generator'] != 'coco')]#& (df['Generator'] != 'ADM')\n",
    "filtered_data = filtered_data[filtered_data['Generator'].isin(Test_Columns)]\n",
    "filtered_data = filtered_data[filtered_data['Generator'] != filtered_data['Experiment']]\n",
    "# filtered_data[\"Number\"] = filtered_data[\"Number\"].replace(\"no\", 200)\n",
    "# filtered_data[\"Number\"] = filtered_data[\"Number\"].astype(int)\n",
    "filtered_data['Number'] = pd.to_numeric(filtered_data['Number'].replace('no', 200))\n",
    "Diffs = [\"DDPM\", \"IDDPM\", \"ADM\", \"PNDM\", \"LDM\"]\n",
    "\n",
    "dino_data_corrected = filtered_data[filtered_data['Encoder'] == 'DinoV2']\n",
    "clip_data = filtered_data[filtered_data['Encoder'] == 'OpenClip']\n",
    "\n",
    "metrics = ['test_pd_01', 'test_recall', 'test_precision']\n",
    "#data = data[data['Generator'] != \"coco\"]\n",
    "#data[\"Number\"].replace(\"no\", 200, inplace=True)\n",
    "blue_palette = sns.color_palette(\"Blues\", len(Gans))\n",
    "red_palette = sns.color_palette(\"Reds\", len(Diffs))\n",
    "#sns.set_palette('deep')\n",
    "head_key = \"Experiment\"\n",
    "y = \"test_acc\"\n",
    "#plt.figure(figsize=(18, len(filtered_data[head_key].unique()) * 6))\n",
    "# Assuming 'data' is a DataFrame that contains all experiments data\n",
    "# 'y' is the column for the y-axis and 'head_key' is the column that distinguishes different experiments\n",
    "# 'Number' is assumed to be the x-axis\n",
    "data = filtered_data\n",
    "global_min_y = data[y].min()\n",
    "global_max_y = data[y].max()\n",
    "\n",
    "# Define a diverse color palette\n",
    "palette = sns.color_palette(\"husl\", n_colors=len(clip_data['Generator'].unique()))\n",
    "\n",
    "# Plot for CLIP encoder\n",
    "# g_clip = sns.FacetGrid(clip_data, col=head_key, hue='Generator', col_wrap=4, sharey=False, palette=palette)\n",
    "# g_clip.map(sns.lineplot, 'Number', y, linewidth=1.5,  dashes=False).set(ylim=(global_min_y, global_max_y))\n",
    "# g_clip.set_titles(\"{col_name}\",fontsize='x-large')\n",
    "# #g_clip.fig.suptitle('Accuarcy Score vs Frequency Information for CLIP Encoder', y=1.05)\n",
    "# g_clip.despine(left=True)\n",
    "\n",
    "# # Update the x-axis to show only every other tick for better readability\n",
    "# for ax in g_clip.axes.flat:\n",
    "#     ax.set_xticks(ax.get_xticks()[::2])\n",
    "#     ax.set_title(ax.get_title(), fontsize=15)\n",
    "# Plot for DINO (DinoV2) encoder\n",
    "subplot_size_width = 7   # Width of each subplot\n",
    "subplot_size_height = 25  # Height of each subplot\n",
    "\n",
    "# Calculate the width of the entire FacetGrid\n",
    "grid_width = subplot_size_width * 3  # Since you want 3 in a row\n",
    "grid_height = subplot_size_height * (len(clip_data[head_key].unique()) // 3 + 1)\n",
    "def create_facetGrid(data, head_key, y, global_min_y, global_max_y, palette):\n",
    "    # Create the FacetGrid\n",
    "    g = sns.FacetGrid(data, col=head_key, hue='Generator', col_wrap=4, sharey=False, palette=palette, height=2.5, aspect=.65)\n",
    "    g.map(sns.lineplot, 'Number', y, linewidth=1.5, dashes=False).set(ylim=(global_min_y, global_max_y))#, xlim=(min_y, max_y)\n",
    "    g.set_titles(\"{col_name}\", fontsize='x-large')\n",
    "\n",
    "    # Adding a horizontal dotted line at y=50\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axhline(50, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Customize x-axis labels\n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_xticks([1, 100, 200])\n",
    "        ax.set_xticklabels(['1', '100', '200'])\n",
    "        ax.tick_params(axis='x', labelbottom=True)  # Ensures x-axis labels are at the bottom\n",
    "        ax.set_title(ax.get_title(), fontsize=15)\n",
    "\n",
    "    # Despine the plots\n",
    "    g.despine(left=True)\n",
    "\n",
    "    return g\n",
    "\n",
    "def create_custom_palette(gans_list, diffs_list):\n",
    "    # Number of unique elements in each list\n",
    "    num_gans = len(gans_list)\n",
    "    num_diffs = len(diffs_list) \n",
    "\n",
    "    # Generate color palettes\n",
    "    blues = sns.color_palette(\"Reds\", num_gans)\n",
    "    reds = sns.color_palette(\"Blues\", num_diffs)\n",
    "\n",
    "    # Map each element to its color\n",
    "    palette = {gan: blues[i] for i, gan in enumerate(gans_list)}\n",
    "    palette.update({diff: reds[i] for i, diff in enumerate(diffs_list)})\n",
    "\n",
    "    return palette\n",
    "\n",
    "\n",
    "def create_single_view(data, head_key, y, global_min_y, global_max_y, palette):\n",
    "    # Create one single view. \n",
    "    sns.lineplot(data=data, x=\"Number\", y=y, hue='Generator', palette=palette, linewidth=1.5, dashes=False)\n",
    "    plt.ylim(global_min_y, global_max_y)\n",
    "    plt.title(head_key, fontsize='x-large')\n",
    "    plt.axhline(50, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.xticks([1,25,50,75, 100,125,150,175,200], [\"1\",\"25\",\"50\",\"75\", \"100\",\"125\",\"150\",\"175\",\"200\"])\n",
    "    #plt.xticks([1, 100, 200])\n",
    "    plt.xlabel('D0')\n",
    "    plt.ylabel(y)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "palette = create_custom_palette(Gans, Diffs)\n",
    "create_single_view(dino_data_corrected, head_key, y, global_min_y, global_max_y, palette)\n",
    "# grid = create_facetGrid(dino_data_corrected, head_key, y, global_min_y, global_max_y, palette)\n",
    "# grid.add_legend(title='Generator', fontsize='x-large', title_fontsize='20', loc='lower right', ncol=2,label_order=Gans+Diffs)\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Display the plots\n",
    "# grid.fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the opservation, that the models trained on the gan images perform worse on the DM generated images, we want to see if this is due to a bias twoards a certain frequency spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Impact of Frequency Removal on the Classification Performace. \n",
    "\n",
    "To Understand if or even which frequency bands are most important for the classification of a given generator, we low pass filter the image using a butterworth filter. Butterworth has the advandge of generating less \"rippels\" aka artifcats in the inverse fourier. So we increase with a step size of 5 the filter, and see how that impacts the classification performance. It is important that we take the False Postive and False Negative Rate into perspective, as a High flase postive would indicate a a fake image dump, while a false negative rate, would indicate a basis towards classifiying images as real. \n",
    "\n",
    "\n",
    "As a first step, we want to compare the two models for all experiments and generators. We do this, to see if there are any specific patterns that are destinc towards the encoder. As coco was trained on a completely different dataset, we exclude it for the analysis, as it would not be a fair comparison. We also remove the performance on the own data.\n",
    "Then we also plot the recall, to see if the model starts to overclassify images a real, even though they are fake. Meaning, it starts to dump images into the real category.\n",
    "\n",
    "Then we also plot the precision, to see if the model starts to overclassify images a fake, even though they are real. Meaning, it starts to dump images into the fake category.\n",
    "\n",
    "\n",
    "As we have seen earlier that the there is a clear difference between models trained on gans and models trained on diff models. We want to see if we can determine which could be the reason for it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df_ce[(df_ce['Experiment'] != 'coco') & (df_ce['Generator'] != 'coco')]#\n",
    "filtered_data = filtered_data[filtered_data['Generator'] != filtered_data['Experiment']]\n",
    "dino_data_corrected = filtered_data[filtered_data['Encoder'] == 'DinoV2']\n",
    "clip_data = filtered_data[filtered_data['Encoder'] == 'OpenClip']\n",
    "metrics = ['test_acc', 'test_recall', 'test_precision']\n",
    "sns.set_palette('deep')\n",
    "\n",
    "dino_data_corrected = dino_data_corrected[(dino_data_corrected[\"Generator\"].isin(Diffs))&(dino_data_corrected[\"Experiment\"].isin(Gans))]\n",
    "clip_data = clip_data[(clip_data[\"Generator\"].isin(Diffs))&(clip_data[\"Experiment\"].isin(Gans))]\n",
    "# Creating a figure for each metric\n",
    "for metric in metrics:\n",
    "    global_min_y = filtered_data[metric].min()\n",
    "    global_max_y = filtered_data[metric].max()\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Convert 'Number' to numeric, replacing 'no' with 200 and sort in descending order\n",
    "    clip_data_sorted = clip_data.copy()\n",
    "    dino_data_sorted = dino_data_corrected.copy()\n",
    "    clip_data_sorted['Number'] = pd.to_numeric(clip_data_sorted['Number'].replace('no', 200))\n",
    "    dino_data_sorted['Number'] = pd.to_numeric(dino_data_sorted['Number'].replace('no', 200))\n",
    "    clip_data_sorted = clip_data_sorted.sort_values(by='Number', ascending=True)\n",
    "    dino_data_sorted = dino_data_sorted.sort_values(by='Number', ascending=True)\n",
    "\n",
    "    # Combined line plot for both CLIP and DINO encoders\n",
    "    if not clip_data_sorted.empty:\n",
    "        sns.lineplot(x='Number', y=metric, data=clip_data_sorted, label='CLIP', ci='sd', markers=True)\n",
    "    if not dino_data_sorted.empty:\n",
    "        sns.lineplot(x='Number', y=metric, data=dino_data_sorted, label='DINO (DinoV2)', ci='sd', markers=True)\n",
    "\n",
    "    plt.xticks(rotation=45)  # Rotating the x-axis labels\n",
    "    plt.xlim(200, 0) \n",
    "    plt.ylim(global_min_y, global_max_y) \n",
    "    plt.title(f'{metric.capitalize().replace(\"test_\", \"\")} vs Frequency Information')\n",
    "    plt.xlabel('Frequency Information (Number)')\n",
    "    plt.ylabel(metric.capitalize().replace(\"test_\", \"\"))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that clip tends to classify all images as fake, if there is no high frequency informaiton. When we give it more frequency information, the rate of missing fake images increases. Dino on the other hand, increases its recall the more information is provided. THis indicated that dino when trained on gan images checks also the low frequency domain, and makes it majority decission based on the highest frequencys. Both models, learned that when focusing on the highest frequenices, they best classify gans generated images, while for dino the lower frequencies also play a role. So if we train the model with the fourier filter, it should be able to better classify new unseen generators, as they can learn to learn to also focus on new bands. \n",
    "When looking a the precission, we see that dino realtivly fasts reduces the false postive rate, meaning to overclassifiying fake images. With dino, the rate slowly increases. So Dino is less likly tricked into thinking a image is fake, with lower frequencies. \n",
    "\n",
    "The data suggest that dino is able to utilize the lower frequency bands aswell for its classification. \n",
    "\n",
    "\n",
    "\n",
    "An idead would be to find the frequency where all models on average perform best for either gan or diff. \n",
    "\n",
    "\n",
    "Gans produce more noise in the higher frequencies then diffusion models. So when trained on gans, the models have problems handling diffusion models, where the noise in the higher frequencies is less distinct. This  has been shown by (paper). So if a model is able to utilize also lower frequencies in a efficient way, it performs should be good till the noisy higher frequecies are introduced. So we see that dino encodes lower frequencies better then clip. Meaning when training clip, the higher frequencies played a more important role in the classificaiton context. Yet in the self supervised training of dino, the lower frequencies play are more crucial role. So while both models utilize the full frequency range, dino handles the lower frequencies better. This is important, is the lower frequecies are less prone to noise, and thus more robust to unseen generators. \n",
    "\n",
    "To now fully utilize the lower frequencies, we want to train the model with a low pass filter. Here it is important to note, that all images need to be lowpass filtered. This is possible as we do not finetune the weights of the encoder it self, which still is able to produce the embeddings of unfilter images correctly, we just ensure that the classification layer is able to focus the lower frequencies. So if the training is succesfull, dino should be able to classify unseen generators better, as it is able to utilize the lower frequencies. If this holds up, the training paradigm for dino does improve foundation models in the sense, that more low frequency information is encoded. This information is important for a variety of tasks, such as ... .\n",
    "\n",
    "When looking into the training paradigm used for dino and clip, it is mentioned in the dino paper they use a gausian blur effect, which is a low pass filter. While in the clip paper they do not use it. This could be the reason why dino is better in focusing on lower frequencies, and in our case it brings a wide range of advantages. So we have a task, which can not soley be solved with higher frequencie information, we should train the model with a low pass filter. This not only reduces the noise in the higher frequencies, but also forces the model to focus on the lower frequencies, which contain valuble information for certain tasks.\n",
    "\n",
    "We hypothesis that dino can better encode lowfrequency information dues to the augmentaitons used during training. In Training they always apply the Gausian Blur on all student data, which forces the model to encode the basic understanding of the image based on those frequencies. As we could see in the privous section, Dino is able to utilize the lower frequencies better then clip. This is important, as the lower frequencies are less prone to noise (paper that shows this). Even more so, it was shown that diffusion models also show artificats in the mid-to high frequenzy range. What is interesting though, is that dino can sperate between gans and dinos in the mid frequency range way better then in the high frequency range.\n",
    "\n",
    "\n",
    "Lowpass filtering does imporve performance. This is contradicting the conjecture claimned int (paper), which states the the lowpass filtering makes them indistinguishable. \n",
    "\n",
    "It is also shown that higher frequencies in diffusion models show simalr artifcats as naturall images in the with jpeg compresseion.(Frourier Diff paper). The same paper delivers the conjecture, that infact mid frequecny deliver \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df[(df['Experiment'] == 'coco') & (df['Generator'] != 'coco')]\n",
    "#filtered_data = filtered_data[filtered_data['Generator'] != filtered_data['Experiment']]\n",
    "dino_data_corrected = filtered_data[filtered_data['Encoder'] == 'DinoV2']\n",
    "clip_data = filtered_data[filtered_data['Encoder'] == 'OpenClip']\n",
    "metrics = ['test_acc', 'test_recall', 'test_precision']\n",
    "sns.set_palette('deep')\n",
    "\n",
    "\n",
    "dino_data_corrected = dino_data_corrected[(dino_data_corrected[\"Generator\"].isin(Diffs))]\n",
    "clip_data = clip_data[(clip_data[\"Generator\"].isin(Diffs))]\n",
    "# Creating a figure for each metric\n",
    "for metric in metrics:\n",
    "    global_min_y = filtered_data[metric].min()\n",
    "    global_max_y = filtered_data[metric].max()\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Boxplot for CLIP encoder\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    sns.boxplot(x='Number', y=metric, data=clip_data)\n",
    "    sns.pointplot(x='Number', y=metric, data=clip_data, color='black', markersize=6, linewidth=2)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylim(global_min_y, global_max_y) \n",
    "    plt.title(f'{metric.capitalize().replace(\"test_\", \"\")} vs Frequency Information for CLIP Encoder')\n",
    "    plt.xlabel('Frequency Information (Number)')\n",
    "    plt.ylabel(metric.capitalize().replace(\"test_\", \"\"))\n",
    "\n",
    "    # Boxplot for DINO (DinoV2) encoder\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if not dino_data_corrected.empty:\n",
    "        sns.boxplot(x='Number', y=metric, data=dino_data_corrected)\n",
    "        sns.pointplot(x='Number', y=metric, data=dino_data_corrected, color='black', markersize=6, linewidth=2)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(global_min_y, global_max_y) \n",
    "        plt.title(f'{metric.capitalize().replace(\"test_\", \"\")} vs Frequency Information for DINO (DinoV2) Encoder')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel(metric.capitalize().replace(\"test_\", \"\"))\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No data available for DINO (DinoV2) Encoder', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title('Data Unavailable for DINO (DinoV2)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check, if face with the same datatype, if model has different behaviour. We\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df[df['Generator'] == df['Experiment']]\n",
    "dino_data_corrected = filtered_data[filtered_data['Encoder'] == 'DinoV2']\n",
    "clip_data = filtered_data[filtered_data['Encoder'] == 'OpenClip']\n",
    "metrics = ['test_f1', 'test_recall', 'test_precision']\n",
    "sns.set_palette('deep')\n",
    "# Creating a figure for each metric\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Boxplot for CLIP encoder\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x='Number', y=metric, data=clip_data)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f'{metric.capitalize().replace(\"test_\", \"\")} vs Frequency Information for CLIP Encoder')\n",
    "    plt.xlabel('Frequency Information (Number)')\n",
    "    plt.ylabel(metric.capitalize().replace(\"test_\", \"\"))\n",
    "\n",
    "    # Boxplot for DINO (DinoV2) encoder\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if not dino_data_corrected.empty:\n",
    "        sns.boxplot(x='Number', y=metric, data=dino_data_corrected)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(f'{metric.capitalize().replace(\"test_\", \"\")} vs Frequency Information for DINO (DinoV2) Encoder')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel(metric.capitalize().replace(\"test_\", \"\"))\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'No data available for DINO (DinoV2) Encoder', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title('Data Unavailable for DINO (DinoV2)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an easy distinction for example in the high frequency specturm for a model, that model should generally be better performing when when a input data also has that aspect. \n",
    "\n",
    "Here we compare how the different experiments behave. To Ensure no domain shift problems within the lsun trained generators. \n",
    "\n",
    "We also seperate between Gans and diffusion trained models. So that the generator will be diffs if trained on a gan and visa versa for diffs.\n",
    "\n",
    "To better compare the plots, we have to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = df\n",
    "data = data[data['Generator'] != \"coco\"]\n",
    "data[\"Number\"].replace(\"no\", 200, inplace=True)\n",
    "dino_data_corrected = data[data['Encoder'] == 'DinoV2']\n",
    "clip_data = data[data['Encoder'] == 'OpenClip']\n",
    "sns.set_palette('deep')\n",
    "head_key = \"Experiment\"\n",
    "y = \"test_f1\"\n",
    "plt.figure(figsize=(18, len(data[head_key].unique()) * 6))\n",
    "\n",
    "# Find global y-axis limits\n",
    "global_min_y = data[y].min()\n",
    "global_max_y = data[y].max()\n",
    "\n",
    "for i, experiment in enumerate(data[head_key].unique()):\n",
    "    dino_experiment_data = dino_data_corrected[dino_data_corrected[head_key] == experiment]\n",
    "    clip_experiment_data = clip_data[clip_data[head_key] == experiment]\n",
    "\n",
    "    # Similar filtering for Gans and Diffs...\n",
    "\n",
    "    if experiment in Gans:\n",
    "        dino_experiment_data = dino_experiment_data[dino_experiment_data[\"Generator\"].isin(Diffs)]\n",
    "        clip_experiment_data = clip_experiment_data[clip_experiment_data[\"Generator\"].isin(Diffs)]\n",
    "    elif experiment in Diffs:\n",
    "        dino_experiment_data = dino_experiment_data[dino_experiment_data[\"Generator\"].isin(Gans)]\n",
    "        clip_experiment_data = clip_experiment_data[clip_experiment_data[\"Generator\"].isin(Gans)]\n",
    "\n",
    "    # Boxplot for CLIP encoder\n",
    "    plt.subplot(len(data[head_key].unique()), 2, 2*i + 1)\n",
    "    if not clip_experiment_data.empty:\n",
    "        sns.boxenplot(x='Number', y=y, data=clip_experiment_data, color='lightgray')\n",
    "        sns.pointplot(x='Number', y=y, data=clip_experiment_data, color='black', scale=0.75)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(global_min_y, global_max_y)  # Set the global y-axis limits\n",
    "        plt.title(f'F1 Score vs Frequency Information for CLIP Encoder - {experiment}')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel('F1 Score')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'No data available for CLIP Encoder - {experiment}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title(f'Data Unavailable for CLIP - {experiment}')\n",
    "\n",
    "    # Boxplot for DINO (DinoV2) encoder\n",
    "    plt.subplot(len(data[head_key].unique()), 2, 2*i + 2)\n",
    "    if not dino_experiment_data.empty:\n",
    "        sns.boxenplot(x='Number', y=y, data=dino_experiment_data, color='lightgray')\n",
    "        sns.pointplot(x='Number', y=y, data=dino_experiment_data, color='black', scale=0.75)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(global_min_y, global_max_y)  # Set the global y-axis limits\n",
    "        plt.title(f'F1 Score vs Frequency Information for DINO (DinoV2) Encoder - {experiment}')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel('F1 Score')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'No data available for DINO (DinoV2) Encoder - {experiment}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title(f'Data Unavailable for DINO (DinoV2) - {experiment}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = df\n",
    "data = data[data['Generator'] != \"coco\"]\n",
    "data[\"Number\"].replace(\"no\", 200, inplace=True)\n",
    "dino_data_corrected = data[data['Encoder'] == 'DinoV2']\n",
    "clip_data = data[data['Encoder'] == 'OpenClip']\n",
    "sns.set_palette('deep')\n",
    "head_key = \"Generator\"\n",
    "y = \"test_acc\"\n",
    "plt.figure(figsize=(18, len(data[head_key].unique()) * 6))\n",
    "\n",
    "# Find global y-axis limits\n",
    "global_min_y = data[y].min()\n",
    "global_max_y = data[y].max()\n",
    "\n",
    "for i, experiment in enumerate(data[head_key].unique()):\n",
    "    dino_experiment_data = dino_data_corrected[dino_data_corrected[head_key] == experiment]\n",
    "    clip_experiment_data = clip_data[clip_data[head_key] == experiment]\n",
    "\n",
    "    # Similar filtering for Gans and Diffs...\n",
    "\n",
    "    # if experiment in Gans:\n",
    "    #     dino_experiment_data = dino_experiment_data[dino_experiment_data[\"Experiment\"].isin(Diffs)]\n",
    "    #     clip_experiment_data = clip_experiment_data[clip_experiment_data[\"Experiment\"].isin(Diffs)]\n",
    "    # elif experiment in Diffs:\n",
    "    #     dino_experiment_data = dino_experiment_data[dino_experiment_data[\"Experiment\"].isin(Gans)]\n",
    "    #     clip_experiment_data = clip_experiment_data[clip_experiment_data[\"Experiment\"].isin(Gans)]\n",
    "\n",
    "    # Boxplot for CLIP encoder\n",
    "    plt.subplot(len(data[head_key].unique()), 2, 2*i + 1)\n",
    "    if not clip_experiment_data.empty:\n",
    "        sns.boxenplot(x='Number', y=y, data=clip_experiment_data, color='lightgray')\n",
    "        sns.pointplot(x='Number', y=y, data=clip_experiment_data, color='black', scale=0.75)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(global_min_y, global_max_y)  # Set the global y-axis limits\n",
    "        plt.title(f'F1 Score vs Frequency Information for CLIP Encoder - {experiment}')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel('F1 Score')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'No data available for CLIP Encoder - {experiment}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title(f'Data Unavailable for CLIP - {experiment}')\n",
    "\n",
    "    # Boxplot for DINO (DinoV2) encoder\n",
    "    plt.subplot(len(data[head_key].unique()), 2, 2*i + 2)\n",
    "    if not dino_experiment_data.empty:\n",
    "        sns.boxenplot(x='Number', y=y, data=dino_experiment_data, color='lightgray')\n",
    "        sns.pointplot(x='Number', y=y, data=dino_experiment_data, color='black', scale=0.75)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylim(global_min_y, global_max_y)  # Set the global y-axis limits\n",
    "        plt.title(f'F1 Score vs Frequency Information for DINO (DinoV2) Encoder - {experiment}')\n",
    "        plt.xlabel('Frequency Information (Number)')\n",
    "        plt.ylabel('F1 Score')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, f'No data available for DINO (DinoV2) Encoder - {experiment}', \n",
    "                 horizontalalignment='center', verticalalignment='center', \n",
    "                 transform=plt.gca().transAxes)\n",
    "        plt.title(f'Data Unavailable for DINO (DinoV2) - {experiment}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = df\n",
    "data = data[data['Generator'] != \"coco\"]\n",
    "data[\"Number\"].replace(\"no\", 200, inplace=True)\n",
    "data[\"Number\"] = data[\"Number\"].astype(str)  # Convert 'Number' to string\n",
    "dino_data = data[data['Encoder'] == 'DinoV2']\n",
    "clip_data = data[data['Encoder'] == 'OpenClip']\n",
    "\n",
    "sns.set_palette('deep')\n",
    "head_key = \"Experiment\"\n",
    "y = \"test_f1\"\n",
    "\n",
    "# Separate experiments into Gans and Diffs\n",
    "experiments_gans = [exp for exp in data[head_key].unique() if exp in Gans]\n",
    "experiments_diffs = [exp for exp in data[head_key].unique() if exp in Diffs]\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, max(len(experiments_gans), len(experiments_diffs)), figsize=(18, 12))\n",
    "\n",
    "for i, experiment in enumerate(experiments_gans):\n",
    "    experiment_data_dino = dino_data[dino_data[head_key] == experiment]\n",
    "    experiment_data_clip = clip_data[clip_data[head_key] == experiment]\n",
    "    \n",
    "    if not experiment_data_dino.empty or not experiment_data_clip.empty:\n",
    "        sns.lineplot(x='Number', y=y, data=experiment_data_dino, label='DinoV2', ci='sd', estimator='mean', ax=axs[0, i])\n",
    "        sns.lineplot(x='Number', y=y, data=experiment_data_clip, label='OpenClip', ci='sd', estimator='mean', ax=axs[0, i])\n",
    "        axs[0, i].set_title(f'Gans - {experiment}')\n",
    "    else:\n",
    "        axs[0, i].text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
    "\n",
    "\n",
    "for j, experiment in enumerate(experiments_diffs):\n",
    "    experiment_data_dino = dino_data[dino_data[head_key] == experiment]\n",
    "    experiment_data_clip = clip_data[clip_data[head_key] == experiment]\n",
    "    \n",
    "    if not experiment_data_dino.empty or not experiment_data_clip.empty:\n",
    "        sns.lineplot(x='Number', y=y, data=experiment_data_dino, label='DinoV2', ci='sd', estimator='mean', ax=axs[1, j])\n",
    "        sns.lineplot(x='Number', y=y, data=experiment_data_clip, label='OpenClip', ci='sd', estimator='mean', ax=axs[1, j])\n",
    "        axs[1, j].set_title(f'Diffs - {experiment}')\n",
    "    else:\n",
    "        axs[1, j].text(0.5, 0.5, 'No data available', ha='center', va='center')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the impact of FDA Swichting on the Classification performance\n",
    "\n",
    "When low frequencies from a real image are injected into a target image, a low recall rate indicates that the model is mistaking fake images for real ones. Initially, this might seem disadvantageous, as it could potentially allow the model to be tricked into classifying an altered image as genuine. However, it could also demonstrate the encoder's proficiency in processing low-level features. Ideally, this capability should result in a real image being correctly identified as real, hence a higher precision score. If the model fails to do so, it effectively creates a repository for misidentified real images. Moreover, the model may inaccurately flag images with unusual frequency characteristics as fake, even when such peculiarities arise from authentic, unaltered sources.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4225d0debf0bf8951841dee0a3187de790889701f15cf4cff14352ec807aab4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
